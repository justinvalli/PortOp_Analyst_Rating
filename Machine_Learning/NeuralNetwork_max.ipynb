{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82a86abe-7cfa-4861-bce5-1bb0c358a708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sell Side Recommendation Model\\n\\nBuild a classification model that replaces the sell-side equity analyst team covering \\na particular stock or index\\n\\n* Output a buy, sell, or hold reccomendation by producing a model that shows \\nthe projected price vs. the street consensus (average of the major wall street bank \\nprice targets vs. our price target)'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Sell Side Recommendation Model\n",
    "\n",
    "Build a classification model that replaces the sell-side equity analyst team covering \n",
    "a particular stock or index\n",
    "\n",
    "* Output a buy, sell, or hold reccomendation by producing a model that shows \n",
    "the projected price vs. the street consensus (average of the major wall street bank \n",
    "price targets vs. our price target)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "502dbce9-11b7-4fd9-ba9e-3c9d7cefec04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Look at a variety of factors that could potentially predict the price action\\nof the stock:\\n* Macro: Yield curve, interest rates \\n* Fundamental: EBITDA, EPS, revenue\\n* Technical: Closing prices, moving averages, VWAP\\n* Sentiment: Sentiment analysis thru NLP '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Look at a variety of factors that could potentially predict the price action\n",
    "of the stock:\n",
    "* Macro: Yield curve, interest rates \n",
    "* Fundamental: EBITDA, EPS, revenue\n",
    "* Technical: Closing prices, moving averages, VWAP\n",
    "* Sentiment: Sentiment analysis thru NLP \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c59330e7-0949-4529-a737-26d9de86e7b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ML MODELS WE WILL USE\\n* random forests\\n* logistic regression\\n* neural network '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"ML MODELS WE WILL USE\n",
    "* random forests\n",
    "* logistic regression\n",
    "* neural network \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c88f687-280d-420f-9471-19bb43e5e229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If the backtested model shows that the stock will move in a certain way, we will use a linear regression\\nof the price to report the anticipated price action (mix of both quantitative and qualitative factors)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"If the backtested model shows that the stock will move in a certain way, we will use a linear regression\n",
    "of the price to report the anticipated price action (mix of both quantitative and qualitative factors)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0757be72-4923-4b59-9e24-601394838bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Finally, incorporate a UI through Streamlit'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Finally, incorporate a UI through Streamlit\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37090c21-ed98-47e9-a620-00b0aed72a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Neural Network using these factors to create a multi-classification model\n",
    "# to determine buy, sell, or hold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53f93c17-f233-4e8d-a868-2b60854c462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "089770b9-123e-473d-8367-ddc1185d7bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_B</th>\n",
       "      <th>_H</th>\n",
       "      <th>_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _B  _H  _S\n",
       "0   1   0   0\n",
       "1   0   1   0\n",
       "2   0   1   0\n",
       "3   0   0   1\n",
       "4   0   0   1\n",
       "5   1   0   0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "target = pd.DataFrame(['B', 'H', 'H', 'S', 'S', 'B'])\n",
    "pd.get_dummies(target, prefix = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a609396-e225-4e8f-8fdf-e97e0d3ef9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>GLD</th>\n",
       "      <th>GLD % Change</th>\n",
       "      <th>VNQ</th>\n",
       "      <th>VNQ % Change</th>\n",
       "      <th>USO</th>\n",
       "      <th>USO % Change</th>\n",
       "      <th>KO</th>\n",
       "      <th>KO % Change</th>\n",
       "      <th>TSLA</th>\n",
       "      <th>...</th>\n",
       "      <th>AGG % Change</th>\n",
       "      <th>JNK</th>\n",
       "      <th>JNK % Change</th>\n",
       "      <th>50 MA</th>\n",
       "      <th>200 MA</th>\n",
       "      <th>Max Sharpe % Change By Weights</th>\n",
       "      <th>1 YR</th>\n",
       "      <th>5 YR</th>\n",
       "      <th>30 YR</th>\n",
       "      <th>Signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-08-18 04:00:00+00:00</td>\n",
       "      <td>175.33</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>80.44</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>72.79</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>60.95</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>215.49</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>90.840000</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.600437</td>\n",
       "      <td>1.633654</td>\n",
       "      <td>5.350000</td>\n",
       "      <td>4.380000</td>\n",
       "      <td>4.380000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-08-17 04:00:00+00:00</td>\n",
       "      <td>175.30</td>\n",
       "      <td>-0.000171</td>\n",
       "      <td>80.19</td>\n",
       "      <td>-0.003108</td>\n",
       "      <td>71.98</td>\n",
       "      <td>-0.011128</td>\n",
       "      <td>60.61</td>\n",
       "      <td>-0.005578</td>\n",
       "      <td>219.22</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002196</td>\n",
       "      <td>90.800000</td>\n",
       "      <td>-0.000440</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>1.600437</td>\n",
       "      <td>1.633654</td>\n",
       "      <td>5.360000</td>\n",
       "      <td>4.420000</td>\n",
       "      <td>4.410000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-08-16 04:00:00+00:00</td>\n",
       "      <td>175.57</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>80.84</td>\n",
       "      <td>0.008106</td>\n",
       "      <td>71.37</td>\n",
       "      <td>-0.008475</td>\n",
       "      <td>60.48</td>\n",
       "      <td>-0.002145</td>\n",
       "      <td>225.60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001048</td>\n",
       "      <td>91.230000</td>\n",
       "      <td>0.004736</td>\n",
       "      <td>0.009146</td>\n",
       "      <td>1.600437</td>\n",
       "      <td>1.633654</td>\n",
       "      <td>5.370000</td>\n",
       "      <td>4.420000</td>\n",
       "      <td>4.380000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-08-15 04:00:00+00:00</td>\n",
       "      <td>176.59</td>\n",
       "      <td>0.005810</td>\n",
       "      <td>81.85</td>\n",
       "      <td>0.012494</td>\n",
       "      <td>72.62</td>\n",
       "      <td>0.017514</td>\n",
       "      <td>60.47</td>\n",
       "      <td>-0.000165</td>\n",
       "      <td>232.96</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002408</td>\n",
       "      <td>91.470000</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.011147</td>\n",
       "      <td>1.600437</td>\n",
       "      <td>1.633654</td>\n",
       "      <td>5.360000</td>\n",
       "      <td>4.360000</td>\n",
       "      <td>4.320000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-08-14 04:00:00+00:00</td>\n",
       "      <td>177.06</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>82.78</td>\n",
       "      <td>0.011362</td>\n",
       "      <td>73.81</td>\n",
       "      <td>0.016387</td>\n",
       "      <td>60.88</td>\n",
       "      <td>0.006780</td>\n",
       "      <td>239.76</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002716</td>\n",
       "      <td>91.760000</td>\n",
       "      <td>0.003170</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>1.600437</td>\n",
       "      <td>1.633654</td>\n",
       "      <td>5.370000</td>\n",
       "      <td>4.360000</td>\n",
       "      <td>4.290000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>2015-12-07 05:00:00+00:00</td>\n",
       "      <td>102.67</td>\n",
       "      <td>-0.001653</td>\n",
       "      <td>78.87</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>11.72</td>\n",
       "      <td>0.003425</td>\n",
       "      <td>43.20</td>\n",
       "      <td>0.004418</td>\n",
       "      <td>231.13</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000369</td>\n",
       "      <td>102.128524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005059</td>\n",
       "      <td>1.396687</td>\n",
       "      <td>1.459326</td>\n",
       "      <td>1.639022</td>\n",
       "      <td>1.929995</td>\n",
       "      <td>2.665611</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>2015-12-04 05:00:00+00:00</td>\n",
       "      <td>104.02</td>\n",
       "      <td>0.013149</td>\n",
       "      <td>79.09</td>\n",
       "      <td>0.002789</td>\n",
       "      <td>12.46</td>\n",
       "      <td>0.063140</td>\n",
       "      <td>43.29</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>230.38</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001476</td>\n",
       "      <td>102.128524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007899</td>\n",
       "      <td>1.399886</td>\n",
       "      <td>1.459466</td>\n",
       "      <td>1.639022</td>\n",
       "      <td>1.929995</td>\n",
       "      <td>2.665611</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>2015-12-03 05:00:00+00:00</td>\n",
       "      <td>101.76</td>\n",
       "      <td>-0.021727</td>\n",
       "      <td>77.61</td>\n",
       "      <td>-0.018713</td>\n",
       "      <td>12.77</td>\n",
       "      <td>0.024880</td>\n",
       "      <td>42.46</td>\n",
       "      <td>-0.019173</td>\n",
       "      <td>232.71</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003234</td>\n",
       "      <td>102.128524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.011650</td>\n",
       "      <td>1.402718</td>\n",
       "      <td>1.459572</td>\n",
       "      <td>1.639022</td>\n",
       "      <td>1.929995</td>\n",
       "      <td>2.665611</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940</th>\n",
       "      <td>2015-12-02 05:00:00+00:00</td>\n",
       "      <td>100.69</td>\n",
       "      <td>-0.010515</td>\n",
       "      <td>78.85</td>\n",
       "      <td>0.015977</td>\n",
       "      <td>12.48</td>\n",
       "      <td>-0.022709</td>\n",
       "      <td>42.77</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>231.99</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007369</td>\n",
       "      <td>102.128524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000903</td>\n",
       "      <td>1.406239</td>\n",
       "      <td>1.459670</td>\n",
       "      <td>1.639022</td>\n",
       "      <td>1.929995</td>\n",
       "      <td>2.665611</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>2015-12-01 05:00:00+00:00</td>\n",
       "      <td>102.28</td>\n",
       "      <td>0.015791</td>\n",
       "      <td>80.49</td>\n",
       "      <td>0.020799</td>\n",
       "      <td>12.95</td>\n",
       "      <td>0.037660</td>\n",
       "      <td>42.89</td>\n",
       "      <td>0.002806</td>\n",
       "      <td>237.19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>102.128524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013807</td>\n",
       "      <td>1.410287</td>\n",
       "      <td>1.459862</td>\n",
       "      <td>1.639022</td>\n",
       "      <td>1.929995</td>\n",
       "      <td>2.665611</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1942 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Date     GLD  GLD % Change    VNQ  VNQ % Change  \\\n",
       "0     2023-08-18 04:00:00+00:00  175.33     -0.000237  80.44      0.000087   \n",
       "1     2023-08-17 04:00:00+00:00  175.30     -0.000171  80.19     -0.003108   \n",
       "2     2023-08-16 04:00:00+00:00  175.57      0.001540  80.84      0.008106   \n",
       "3     2023-08-15 04:00:00+00:00  176.59      0.005810  81.85      0.012494   \n",
       "4     2023-08-14 04:00:00+00:00  177.06      0.002662  82.78      0.011362   \n",
       "...                         ...     ...           ...    ...           ...   \n",
       "1937  2015-12-07 05:00:00+00:00  102.67     -0.001653  78.87      0.000888   \n",
       "1938  2015-12-04 05:00:00+00:00  104.02      0.013149  79.09      0.002789   \n",
       "1939  2015-12-03 05:00:00+00:00  101.76     -0.021727  77.61     -0.018713   \n",
       "1940  2015-12-02 05:00:00+00:00  100.69     -0.010515  78.85      0.015977   \n",
       "1941  2015-12-01 05:00:00+00:00  102.28      0.015791  80.49      0.020799   \n",
       "\n",
       "        USO  USO % Change     KO  KO % Change    TSLA  ...  AGG % Change  \\\n",
       "0     72.79      0.000105  60.95    -0.000109  215.49  ...      0.000072   \n",
       "1     71.98     -0.011128  60.61    -0.005578  219.22  ...     -0.002196   \n",
       "2     71.37     -0.008475  60.48    -0.002145  225.60  ...      0.001048   \n",
       "3     72.62      0.017514  60.47    -0.000165  232.96  ...      0.002408   \n",
       "4     73.81      0.016387  60.88     0.006780  239.76  ...      0.002716   \n",
       "...     ...           ...    ...          ...     ...  ...           ...   \n",
       "1937  11.72      0.003425  43.20     0.004418  231.13  ...     -0.000369   \n",
       "1938  12.46      0.063140  43.29     0.002083  230.38  ...     -0.001476   \n",
       "1939  12.77      0.024880  42.46    -0.019173  232.71  ...     -0.003234   \n",
       "1940  12.48     -0.022709  42.77     0.007301  231.99  ...      0.007369   \n",
       "1941  12.95      0.037660  42.89     0.002806  237.19  ...      0.001242   \n",
       "\n",
       "             JNK  JNK % Change     50 MA    200 MA  \\\n",
       "0      90.840000      0.000104  0.000000  1.600437   \n",
       "1      90.800000     -0.000440  0.001484  1.600437   \n",
       "2      91.230000      0.004736  0.009146  1.600437   \n",
       "3      91.470000      0.002631  0.011147  1.600437   \n",
       "4      91.760000      0.003170  0.012008  1.600437   \n",
       "...          ...           ...       ...       ...   \n",
       "1937  102.128524      0.000000  0.005059  1.396687   \n",
       "1938  102.128524      0.000000  0.007899  1.399886   \n",
       "1939  102.128524      0.000000 -0.011650  1.402718   \n",
       "1940  102.128524      0.000000 -0.000903  1.406239   \n",
       "1941  102.128524      0.000000  0.013807  1.410287   \n",
       "\n",
       "      Max Sharpe % Change By Weights      1 YR      5 YR     30 YR  Signal  \n",
       "0                           1.633654  5.350000  4.380000  4.380000       0  \n",
       "1                           1.633654  5.360000  4.420000  4.410000       1  \n",
       "2                           1.633654  5.370000  4.420000  4.380000       1  \n",
       "3                           1.633654  5.360000  4.360000  4.320000       1  \n",
       "4                           1.633654  5.370000  4.360000  4.290000       1  \n",
       "...                              ...       ...       ...       ...     ...  \n",
       "1937                        1.459326  1.639022  1.929995  2.665611       1  \n",
       "1938                        1.459466  1.639022  1.929995  2.665611       1  \n",
       "1939                        1.459572  1.639022  1.929995  2.665611       0  \n",
       "1940                        1.459670  1.639022  1.929995  2.665611       0  \n",
       "1941                        1.459862  1.639022  1.929995  2.665611       1  \n",
       "\n",
       "[1942 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the applicants_data.csv file from the Resources folder into a Pandas DataFrame\n",
    "AAPL_data_df = df = pd.read_csv(\n",
    "    Path(\"max_rating.csv\") \n",
    ")\n",
    "\n",
    "\n",
    "# Review the DataFrame\n",
    "AAPL_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92b577c9-894e-49ab-afd3-622ff3fe6bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date                               object\n",
      "GLD                               float64\n",
      "GLD % Change                      float64\n",
      "VNQ                               float64\n",
      "VNQ % Change                      float64\n",
      "USO                               float64\n",
      "USO % Change                      float64\n",
      "KO                                float64\n",
      "KO % Change                       float64\n",
      "TSLA                              float64\n",
      "TSLA % Change                     float64\n",
      "AAPL                              float64\n",
      "AAPL % Change                     float64\n",
      "AGG                               float64\n",
      "AGG % Change                      float64\n",
      "JNK                               float64\n",
      "JNK % Change                      float64\n",
      "50 MA                             float64\n",
      "200 MA                            float64\n",
      "Max Sharpe % Change By Weights    float64\n",
      "1 YR                              float64\n",
      "5 YR                              float64\n",
      "30 YR                             float64\n",
      "Signal                              int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Review the data types associated with the columns\n",
    "print(AAPL_data_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6016809-6d03-4d98-a14f-c34db9fcb887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Signal']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of categorical variables\n",
    "categorical_variables = AAPL_data_df[['Signal']].columns.tolist()\n",
    "\n",
    "# Display the categorical variables list\n",
    "categorical_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55c2834f-c046-40c6-a695-bf9d12bee8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cd19a69-3594-4b0a-aa29-138a74197666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the categorcal variables using OneHotEncoder\n",
    "encoded_data = enc.fit_transform(AAPL_data_df[categorical_variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e53080d-3e8f-4922-9fac-139f846fd239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Signal_0</th>\n",
       "      <th>Signal_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1942 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Signal_0  Signal_1\n",
       "0          1.0       0.0\n",
       "1          0.0       1.0\n",
       "2          0.0       1.0\n",
       "3          0.0       1.0\n",
       "4          0.0       1.0\n",
       "...        ...       ...\n",
       "1937       0.0       1.0\n",
       "1938       0.0       1.0\n",
       "1939       1.0       0.0\n",
       "1940       1.0       0.0\n",
       "1941       0.0       1.0\n",
       "\n",
       "[1942 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame with the encoded variables\n",
    "encoded_df = pd.DataFrame(encoded_data, columns = enc.get_feature_names_out(categorical_variables))\n",
    "\n",
    "# Review the DataFrame\n",
    "encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48ac2beb-a102-48e2-b246-16b30f5716ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Signal_0</th>\n",
       "      <th>Signal_1</th>\n",
       "      <th>GLD</th>\n",
       "      <th>GLD % Change</th>\n",
       "      <th>VNQ</th>\n",
       "      <th>VNQ % Change</th>\n",
       "      <th>USO</th>\n",
       "      <th>USO % Change</th>\n",
       "      <th>KO</th>\n",
       "      <th>KO % Change</th>\n",
       "      <th>...</th>\n",
       "      <th>AGG % Change</th>\n",
       "      <th>JNK</th>\n",
       "      <th>JNK % Change</th>\n",
       "      <th>50 MA</th>\n",
       "      <th>200 MA</th>\n",
       "      <th>Max Sharpe % Change By Weights</th>\n",
       "      <th>1 YR</th>\n",
       "      <th>5 YR</th>\n",
       "      <th>30 YR</th>\n",
       "      <th>Signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.33</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>80.44</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>72.79</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>60.95</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>90.840000</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.600437</td>\n",
       "      <td>1.633654</td>\n",
       "      <td>5.350000</td>\n",
       "      <td>4.380000</td>\n",
       "      <td>4.380000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>175.30</td>\n",
       "      <td>-0.000171</td>\n",
       "      <td>80.19</td>\n",
       "      <td>-0.003108</td>\n",
       "      <td>71.98</td>\n",
       "      <td>-0.011128</td>\n",
       "      <td>60.61</td>\n",
       "      <td>-0.005578</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002196</td>\n",
       "      <td>90.800000</td>\n",
       "      <td>-0.000440</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>1.600437</td>\n",
       "      <td>1.633654</td>\n",
       "      <td>5.360000</td>\n",
       "      <td>4.420000</td>\n",
       "      <td>4.410000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>175.57</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>80.84</td>\n",
       "      <td>0.008106</td>\n",
       "      <td>71.37</td>\n",
       "      <td>-0.008475</td>\n",
       "      <td>60.48</td>\n",
       "      <td>-0.002145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001048</td>\n",
       "      <td>91.230000</td>\n",
       "      <td>0.004736</td>\n",
       "      <td>0.009146</td>\n",
       "      <td>1.600437</td>\n",
       "      <td>1.633654</td>\n",
       "      <td>5.370000</td>\n",
       "      <td>4.420000</td>\n",
       "      <td>4.380000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>176.59</td>\n",
       "      <td>0.005810</td>\n",
       "      <td>81.85</td>\n",
       "      <td>0.012494</td>\n",
       "      <td>72.62</td>\n",
       "      <td>0.017514</td>\n",
       "      <td>60.47</td>\n",
       "      <td>-0.000165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002408</td>\n",
       "      <td>91.470000</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.011147</td>\n",
       "      <td>1.600437</td>\n",
       "      <td>1.633654</td>\n",
       "      <td>5.360000</td>\n",
       "      <td>4.360000</td>\n",
       "      <td>4.320000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>177.06</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>82.78</td>\n",
       "      <td>0.011362</td>\n",
       "      <td>73.81</td>\n",
       "      <td>0.016387</td>\n",
       "      <td>60.88</td>\n",
       "      <td>0.006780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002716</td>\n",
       "      <td>91.760000</td>\n",
       "      <td>0.003170</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>1.600437</td>\n",
       "      <td>1.633654</td>\n",
       "      <td>5.370000</td>\n",
       "      <td>4.360000</td>\n",
       "      <td>4.290000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102.67</td>\n",
       "      <td>-0.001653</td>\n",
       "      <td>78.87</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>11.72</td>\n",
       "      <td>0.003425</td>\n",
       "      <td>43.20</td>\n",
       "      <td>0.004418</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000369</td>\n",
       "      <td>102.128524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005059</td>\n",
       "      <td>1.396687</td>\n",
       "      <td>1.459326</td>\n",
       "      <td>1.639022</td>\n",
       "      <td>1.929995</td>\n",
       "      <td>2.665611</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104.02</td>\n",
       "      <td>0.013149</td>\n",
       "      <td>79.09</td>\n",
       "      <td>0.002789</td>\n",
       "      <td>12.46</td>\n",
       "      <td>0.063140</td>\n",
       "      <td>43.29</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001476</td>\n",
       "      <td>102.128524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007899</td>\n",
       "      <td>1.399886</td>\n",
       "      <td>1.459466</td>\n",
       "      <td>1.639022</td>\n",
       "      <td>1.929995</td>\n",
       "      <td>2.665611</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.76</td>\n",
       "      <td>-0.021727</td>\n",
       "      <td>77.61</td>\n",
       "      <td>-0.018713</td>\n",
       "      <td>12.77</td>\n",
       "      <td>0.024880</td>\n",
       "      <td>42.46</td>\n",
       "      <td>-0.019173</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003234</td>\n",
       "      <td>102.128524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.011650</td>\n",
       "      <td>1.402718</td>\n",
       "      <td>1.459572</td>\n",
       "      <td>1.639022</td>\n",
       "      <td>1.929995</td>\n",
       "      <td>2.665611</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.69</td>\n",
       "      <td>-0.010515</td>\n",
       "      <td>78.85</td>\n",
       "      <td>0.015977</td>\n",
       "      <td>12.48</td>\n",
       "      <td>-0.022709</td>\n",
       "      <td>42.77</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007369</td>\n",
       "      <td>102.128524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000903</td>\n",
       "      <td>1.406239</td>\n",
       "      <td>1.459670</td>\n",
       "      <td>1.639022</td>\n",
       "      <td>1.929995</td>\n",
       "      <td>2.665611</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102.28</td>\n",
       "      <td>0.015791</td>\n",
       "      <td>80.49</td>\n",
       "      <td>0.020799</td>\n",
       "      <td>12.95</td>\n",
       "      <td>0.037660</td>\n",
       "      <td>42.89</td>\n",
       "      <td>0.002806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>102.128524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013807</td>\n",
       "      <td>1.410287</td>\n",
       "      <td>1.459862</td>\n",
       "      <td>1.639022</td>\n",
       "      <td>1.929995</td>\n",
       "      <td>2.665611</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1942 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Signal_0  Signal_1     GLD  GLD % Change    VNQ  VNQ % Change    USO  \\\n",
       "0          1.0       0.0  175.33     -0.000237  80.44      0.000087  72.79   \n",
       "1          0.0       1.0  175.30     -0.000171  80.19     -0.003108  71.98   \n",
       "2          0.0       1.0  175.57      0.001540  80.84      0.008106  71.37   \n",
       "3          0.0       1.0  176.59      0.005810  81.85      0.012494  72.62   \n",
       "4          0.0       1.0  177.06      0.002662  82.78      0.011362  73.81   \n",
       "...        ...       ...     ...           ...    ...           ...    ...   \n",
       "1937       0.0       1.0  102.67     -0.001653  78.87      0.000888  11.72   \n",
       "1938       0.0       1.0  104.02      0.013149  79.09      0.002789  12.46   \n",
       "1939       1.0       0.0  101.76     -0.021727  77.61     -0.018713  12.77   \n",
       "1940       1.0       0.0  100.69     -0.010515  78.85      0.015977  12.48   \n",
       "1941       0.0       1.0  102.28      0.015791  80.49      0.020799  12.95   \n",
       "\n",
       "      USO % Change     KO  KO % Change  ...  AGG % Change         JNK  \\\n",
       "0         0.000105  60.95    -0.000109  ...      0.000072   90.840000   \n",
       "1        -0.011128  60.61    -0.005578  ...     -0.002196   90.800000   \n",
       "2        -0.008475  60.48    -0.002145  ...      0.001048   91.230000   \n",
       "3         0.017514  60.47    -0.000165  ...      0.002408   91.470000   \n",
       "4         0.016387  60.88     0.006780  ...      0.002716   91.760000   \n",
       "...            ...    ...          ...  ...           ...         ...   \n",
       "1937      0.003425  43.20     0.004418  ...     -0.000369  102.128524   \n",
       "1938      0.063140  43.29     0.002083  ...     -0.001476  102.128524   \n",
       "1939      0.024880  42.46    -0.019173  ...     -0.003234  102.128524   \n",
       "1940     -0.022709  42.77     0.007301  ...      0.007369  102.128524   \n",
       "1941      0.037660  42.89     0.002806  ...      0.001242  102.128524   \n",
       "\n",
       "      JNK % Change     50 MA    200 MA  Max Sharpe % Change By Weights  \\\n",
       "0         0.000104  0.000000  1.600437                        1.633654   \n",
       "1        -0.000440  0.001484  1.600437                        1.633654   \n",
       "2         0.004736  0.009146  1.600437                        1.633654   \n",
       "3         0.002631  0.011147  1.600437                        1.633654   \n",
       "4         0.003170  0.012008  1.600437                        1.633654   \n",
       "...            ...       ...       ...                             ...   \n",
       "1937      0.000000  0.005059  1.396687                        1.459326   \n",
       "1938      0.000000  0.007899  1.399886                        1.459466   \n",
       "1939      0.000000 -0.011650  1.402718                        1.459572   \n",
       "1940      0.000000 -0.000903  1.406239                        1.459670   \n",
       "1941      0.000000  0.013807  1.410287                        1.459862   \n",
       "\n",
       "          1 YR      5 YR     30 YR  Signal  \n",
       "0     5.350000  4.380000  4.380000       0  \n",
       "1     5.360000  4.420000  4.410000       1  \n",
       "2     5.370000  4.420000  4.380000       1  \n",
       "3     5.360000  4.360000  4.320000       1  \n",
       "4     5.370000  4.360000  4.290000       1  \n",
       "...        ...       ...       ...     ...  \n",
       "1937  1.639022  1.929995  2.665611       1  \n",
       "1938  1.639022  1.929995  2.665611       1  \n",
       "1939  1.639022  1.929995  2.665611       0  \n",
       "1940  1.639022  1.929995  2.665611       0  \n",
       "1941  1.639022  1.929995  2.665611       1  \n",
       "\n",
       "[1942 rows x 25 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the numerical variables from the original DataFrame to the one-hot encoding DataFrame\n",
    "numerical_variables = AAPL_data_df.select_dtypes([\"int64\", \"float64\"])\n",
    "encoded_df = pd.concat([encoded_df, numerical_variables], axis = 1)\n",
    "\n",
    "# Review the Dataframe\n",
    "encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b0697cb-209b-4558-a44a-0b123e6fac91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "1937    1\n",
       "1938    1\n",
       "1939    0\n",
       "1940    0\n",
       "1941    1\n",
       "Name: Signal, Length: 1942, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the target set y using the \"Target - B/H/S (based on close - daily % change\") column\n",
    "y = encoded_df[\"Signal\"]\n",
    "\n",
    "# Display a sample of y\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e64bbe27-726b-4699-8b3c-b17c79dd2c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Signal_0                          float64\n",
       "Signal_1                          float64\n",
       "GLD                               float64\n",
       "GLD % Change                      float64\n",
       "VNQ                               float64\n",
       "VNQ % Change                      float64\n",
       "USO                               float64\n",
       "USO % Change                      float64\n",
       "KO                                float64\n",
       "KO % Change                       float64\n",
       "TSLA                              float64\n",
       "TSLA % Change                     float64\n",
       "AAPL                              float64\n",
       "AAPL % Change                     float64\n",
       "AGG                               float64\n",
       "AGG % Change                      float64\n",
       "JNK                               float64\n",
       "JNK % Change                      float64\n",
       "50 MA                             float64\n",
       "200 MA                            float64\n",
       "Max Sharpe % Change By Weights    float64\n",
       "1 YR                              float64\n",
       "5 YR                              float64\n",
       "30 YR                             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define features set X by selecting all columns but IS_SUCCESSFUL\n",
    "X = encoded_df.drop(columns = \"Signal\")\n",
    "\n",
    "# Review the features DataFrame\n",
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df2d9c81-1999-4959-906a-cce7954940e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the preprocessed data into a training and testing dataset\n",
    "# Assign the function a random_state equal to 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81275e65-ca5c-45aa-9e9d-0a78f0e32001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the features training dataset\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Fit the scaler to the features training dataset\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "411faf05-130c-4b6f-ac11-045d2719306e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the the number of inputs (features) to the model\n",
    "number_input_features = number_input_features = X_train_scaled.shape[1]\n",
    "\n",
    "# Review the number of features\n",
    "number_input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1278b0cb-08d3-4475-ac2a-afb3021d30d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of neurons in the output layer\n",
    "number_output_neurons = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6045d1f-12df-4117-8c6b-e6b224de897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hidden layer 1 and 2\n",
    "\n",
    "hidden_nodes_layer1 = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "269d5ed0-783c-4ea6-ba60-1f3c78ce71d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Sequential model instance\n",
    "nn = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eaac5280-a861-4dd0-b4f7-e5c5a1c26675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the first hidden layer\n",
    "nn.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0fafea3-9c1e-4671-a1e9-144639015bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the output layer to the model specifying the number of output neurons and activation function\n",
    "nn.add(Dense(units=number_output_neurons, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5641a7db-2dff-4037-bd9a-1a21cfe6fc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 11)                275       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 287\n",
      "Trainable params: 287\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Display the Sequential model summary\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b893782-5639-4a79-abb8-2994f3f8afb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "46/46 [==============================] - 1s 1ms/step - loss: 0.2910 - accuracy: 0.3661\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2464 - accuracy: 0.5584\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2104 - accuracy: 0.8441\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1797 - accuracy: 0.9354\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1520 - accuracy: 0.9677\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1270 - accuracy: 0.9835\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1050 - accuracy: 0.9897\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0861 - accuracy: 0.9931\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.9952\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0575 - accuracy: 0.9966\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0472 - accuracy: 0.9966\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0389 - accuracy: 0.9979\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0323 - accuracy: 0.9986\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0270 - accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0228 - accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0194 - accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0126 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Compile the Sequential model\n",
    "nn.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06374387-bfd2-4439-a7e4-f865217505c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method compile in module keras.engine.training:\n",
      "\n",
      "compile(optimizer='rmsprop', loss=None, metrics=None, loss_weights=None, weighted_metrics=None, run_eagerly=None, steps_per_execution=None, jit_compile=None, **kwargs) method of keras.engine.sequential.Sequential instance\n",
      "    Configures the model for training.\n",
      "    \n",
      "    Example:\n",
      "    \n",
      "    ```python\n",
      "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
      "                  loss=tf.keras.losses.BinaryCrossentropy(),\n",
      "                  metrics=[tf.keras.metrics.BinaryAccuracy(),\n",
      "                           tf.keras.metrics.FalseNegatives()])\n",
      "    ```\n",
      "    \n",
      "    Args:\n",
      "        optimizer: String (name of optimizer) or optimizer instance. See\n",
      "          `tf.keras.optimizers`.\n",
      "        loss: Loss function. May be a string (name of loss function), or\n",
      "          a `tf.keras.losses.Loss` instance. See `tf.keras.losses`. A loss\n",
      "          function is any callable with the signature `loss = fn(y_true,\n",
      "          y_pred)`, where `y_true` are the ground truth values, and\n",
      "          `y_pred` are the model's predictions.\n",
      "          `y_true` should have shape\n",
      "          `(batch_size, d0, .. dN)` (except in the case of\n",
      "          sparse loss functions such as\n",
      "          sparse categorical crossentropy which expects integer arrays of\n",
      "          shape `(batch_size, d0, .. dN-1)`).\n",
      "          `y_pred` should have shape `(batch_size, d0, .. dN)`.\n",
      "          The loss function should return a float tensor.\n",
      "          If a custom `Loss` instance is\n",
      "          used and reduction is set to `None`, return value has shape\n",
      "          `(batch_size, d0, .. dN-1)` i.e. per-sample or per-timestep loss\n",
      "          values; otherwise, it is a scalar. If the model has multiple\n",
      "          outputs, you can use a different loss on each output by passing a\n",
      "          dictionary or a list of losses. The loss value that will be\n",
      "          minimized by the model will then be the sum of all individual\n",
      "          losses, unless `loss_weights` is specified.\n",
      "        metrics: List of metrics to be evaluated by the model during\n",
      "          training and testing. Each of this can be a string (name of a\n",
      "          built-in function), function or a `tf.keras.metrics.Metric`\n",
      "          instance. See `tf.keras.metrics`. Typically you will use\n",
      "          `metrics=['accuracy']`.\n",
      "          A function is any callable with the signature `result = fn(y_true,\n",
      "          y_pred)`. To specify different metrics for different outputs of a\n",
      "          multi-output model, you could also pass a dictionary, such as\n",
      "          `metrics={'output_a':'accuracy', 'output_b':['accuracy', 'mse']}`.\n",
      "          You can also pass a list to specify a metric or a list of metrics\n",
      "          for each output, such as\n",
      "          `metrics=[['accuracy'], ['accuracy', 'mse']]`\n",
      "          or `metrics=['accuracy', ['accuracy', 'mse']]`. When you pass the\n",
      "          strings 'accuracy' or 'acc', we convert this to one of\n",
      "          `tf.keras.metrics.BinaryAccuracy`,\n",
      "          `tf.keras.metrics.CategoricalAccuracy`,\n",
      "          `tf.keras.metrics.SparseCategoricalAccuracy` based on the shapes\n",
      "          of the targets and of the model output. We do a similar\n",
      "          conversion for the strings 'crossentropy' and 'ce' as well.\n",
      "          The metrics passed here are evaluated without sample weighting; if\n",
      "          you would like sample weighting to apply, you can specify your\n",
      "          metrics via the `weighted_metrics` argument instead.\n",
      "        loss_weights: Optional list or dictionary specifying scalar\n",
      "          coefficients (Python floats) to weight the loss contributions of\n",
      "          different model outputs. The loss value that will be minimized by\n",
      "          the model will then be the *weighted sum* of all individual\n",
      "          losses, weighted by the `loss_weights` coefficients.  If a list,\n",
      "          it is expected to have a 1:1 mapping to the model's outputs. If a\n",
      "          dict, it is expected to map output names (strings) to scalar\n",
      "          coefficients.\n",
      "        weighted_metrics: List of metrics to be evaluated and weighted by\n",
      "          `sample_weight` or `class_weight` during training and testing.\n",
      "        run_eagerly: Bool. Defaults to `False`. If `True`, this `Model`'s\n",
      "          logic will not be wrapped in a `tf.function`. Recommended to leave\n",
      "          this as `None` unless your `Model` cannot be run inside a\n",
      "          `tf.function`. `run_eagerly=True` is not supported when using\n",
      "          `tf.distribute.experimental.ParameterServerStrategy`.\n",
      "        steps_per_execution: Int. Defaults to 1. The number of batches to\n",
      "          run during each `tf.function` call. Running multiple batches\n",
      "          inside a single `tf.function` call can greatly improve performance\n",
      "          on TPUs or small models with a large Python overhead. At most, one\n",
      "          full epoch will be run each execution. If a number larger than the\n",
      "          size of the epoch is passed, the execution will be truncated to\n",
      "          the size of the epoch. Note that if `steps_per_execution` is set\n",
      "          to `N`, `Callback.on_batch_begin` and `Callback.on_batch_end`\n",
      "          methods will only be called every `N` batches (i.e. before/after\n",
      "          each `tf.function` execution).\n",
      "        jit_compile: If `True`, compile the model training step with XLA.\n",
      "          [XLA](https://www.tensorflow.org/xla) is an optimizing compiler\n",
      "          for machine learning.\n",
      "          `jit_compile` is not enabled for by default.\n",
      "          Note that `jit_compile=True`\n",
      "          may not necessarily work for all models.\n",
      "          For more information on supported operations please refer to the\n",
      "          [XLA documentation](https://www.tensorflow.org/xla).\n",
      "          Also refer to\n",
      "          [known XLA issues](https://www.tensorflow.org/xla/known_issues)\n",
      "          for more details.\n",
      "        **kwargs: Arguments supported for backwards compatibility only.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nn.compile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69d48a83-e1d7-4209-a15b-5fe402e84e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.11355287e+00,  1.11355287e+00,  9.26977147e-01, ...,\n",
       "        -8.40166902e-01, -6.16037587e-01, -1.08700655e+00],\n",
       "       [ 8.98026510e-01, -8.98026510e-01,  8.54334349e-01, ...,\n",
       "        -1.06165076e+00, -1.03359515e+00, -6.16314438e-01],\n",
       "       [-1.11355287e+00,  1.11355287e+00,  1.52932337e+00, ...,\n",
       "         2.46866774e+00,  1.90786593e+00,  1.68009252e+00],\n",
       "       ...,\n",
       "       [ 8.98026510e-01, -8.98026510e-01, -1.68580759e+00, ...,\n",
       "        -1.86945860e-03,  5.65443197e-03,  5.01450343e-03],\n",
       "       [-1.11355287e+00,  1.11355287e+00,  6.24626042e-01, ...,\n",
       "         1.36124844e+00,  1.41607591e+00,  1.15234682e+00],\n",
       "       [ 8.98026510e-01, -8.98026510e-01, -7.70115677e-01, ...,\n",
       "         4.55178099e-01,  1.72682262e-01,  1.25382221e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "311a46f6-de65-4eeb-92b8-7e15868ff052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Loss: 0.0011531019117683172, Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "# Display the model loss and accuracy results\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad71923b-a86d-42f2-8e49-8a8f1028c925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1094    0\n",
       "793     0\n",
       "1093    0\n",
       "736     1\n",
       "1112    0\n",
       "1702    1\n",
       "1307    0\n",
       "190     0\n",
       "1296    0\n",
       "1845    1\n",
       "137     0\n",
       "1274    1\n",
       "1421    1\n",
       "1886    1\n",
       "654     0\n",
       "Name: Signal, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a2609e9-c378-4b17-a5cd-d8a1fcdf54be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.04666483],\n",
       "       [0.02373912],\n",
       "       [0.04090839],\n",
       "       [0.9655086 ],\n",
       "       [0.02661311],\n",
       "       [0.9647866 ],\n",
       "       [0.02343876],\n",
       "       [0.02206425],\n",
       "       [0.02480142],\n",
       "       [0.9711241 ],\n",
       "       [0.0308776 ],\n",
       "       [0.97613984],\n",
       "       [0.96221226],\n",
       "       [0.9701509 ],\n",
       "       [0.03374162],\n",
       "       [0.01899808],\n",
       "       [0.06562143],\n",
       "       [0.9829995 ],\n",
       "       [0.03098791],\n",
       "       [0.95899045],\n",
       "       [0.9480077 ],\n",
       "       [0.9265459 ],\n",
       "       [0.03844362],\n",
       "       [0.02285741],\n",
       "       [0.02969537],\n",
       "       [0.04570319],\n",
       "       [0.9610355 ],\n",
       "       [0.04727262],\n",
       "       [0.03183293],\n",
       "       [0.93954515],\n",
       "       [0.0418361 ],\n",
       "       [0.9678295 ],\n",
       "       [0.98377144],\n",
       "       [0.9788851 ],\n",
       "       [0.958107  ],\n",
       "       [0.9884604 ],\n",
       "       [0.01990079],\n",
       "       [0.03644571],\n",
       "       [0.02038827],\n",
       "       [0.02330905],\n",
       "       [0.97246397],\n",
       "       [0.01787865],\n",
       "       [0.03446795],\n",
       "       [0.9888806 ],\n",
       "       [0.03788675],\n",
       "       [0.0375074 ],\n",
       "       [0.01497337],\n",
       "       [0.96232575],\n",
       "       [0.96847   ],\n",
       "       [0.9814023 ],\n",
       "       [0.958171  ],\n",
       "       [0.9524589 ],\n",
       "       [0.03244347],\n",
       "       [0.0330723 ],\n",
       "       [0.02934408],\n",
       "       [0.98159945],\n",
       "       [0.02623428],\n",
       "       [0.04519221],\n",
       "       [0.9461729 ],\n",
       "       [0.96193445],\n",
       "       [0.03584469],\n",
       "       [0.03323484],\n",
       "       [0.02449706],\n",
       "       [0.03885253],\n",
       "       [0.01466755],\n",
       "       [0.02282751],\n",
       "       [0.93820536],\n",
       "       [0.950741  ],\n",
       "       [0.02071522],\n",
       "       [0.02247117],\n",
       "       [0.02713341],\n",
       "       [0.04089406],\n",
       "       [0.01944073],\n",
       "       [0.02133862],\n",
       "       [0.9613184 ],\n",
       "       [0.03179234],\n",
       "       [0.94835275],\n",
       "       [0.02075736],\n",
       "       [0.9783131 ],\n",
       "       [0.98814034],\n",
       "       [0.01619163],\n",
       "       [0.0421977 ],\n",
       "       [0.02664137],\n",
       "       [0.9831837 ],\n",
       "       [0.02348756],\n",
       "       [0.02201946],\n",
       "       [0.9575488 ],\n",
       "       [0.96881807],\n",
       "       [0.97772896],\n",
       "       [0.95269847],\n",
       "       [0.03321569],\n",
       "       [0.9718013 ],\n",
       "       [0.9797966 ],\n",
       "       [0.95919514],\n",
       "       [0.0259352 ],\n",
       "       [0.0253472 ],\n",
       "       [0.9763013 ],\n",
       "       [0.03298901],\n",
       "       [0.02733227],\n",
       "       [0.05018637],\n",
       "       [0.02665559],\n",
       "       [0.9590097 ],\n",
       "       [0.02960005],\n",
       "       [0.9892527 ],\n",
       "       [0.96813685],\n",
       "       [0.02329244],\n",
       "       [0.02222448],\n",
       "       [0.02406812],\n",
       "       [0.02383439],\n",
       "       [0.97228515],\n",
       "       [0.03497891],\n",
       "       [0.05638628],\n",
       "       [0.01755534],\n",
       "       [0.02333731],\n",
       "       [0.04711025],\n",
       "       [0.0250119 ],\n",
       "       [0.9805621 ],\n",
       "       [0.9711033 ],\n",
       "       [0.02578734],\n",
       "       [0.97117996],\n",
       "       [0.03361325],\n",
       "       [0.0344625 ],\n",
       "       [0.9640938 ],\n",
       "       [0.9506054 ],\n",
       "       [0.9532641 ],\n",
       "       [0.9593042 ],\n",
       "       [0.98863405],\n",
       "       [0.02470687],\n",
       "       [0.04701952],\n",
       "       [0.9621687 ],\n",
       "       [0.03058414],\n",
       "       [0.03304157],\n",
       "       [0.976005  ],\n",
       "       [0.95925325],\n",
       "       [0.02239614],\n",
       "       [0.974044  ],\n",
       "       [0.9445101 ],\n",
       "       [0.9536136 ],\n",
       "       [0.98543304],\n",
       "       [0.02374118],\n",
       "       [0.9521374 ],\n",
       "       [0.9699676 ],\n",
       "       [0.9854923 ],\n",
       "       [0.96432537],\n",
       "       [0.02852248],\n",
       "       [0.97102636],\n",
       "       [0.01390331],\n",
       "       [0.03559462],\n",
       "       [0.9783533 ],\n",
       "       [0.03266762],\n",
       "       [0.9661275 ],\n",
       "       [0.03169233],\n",
       "       [0.04930004],\n",
       "       [0.02552802],\n",
       "       [0.02361674],\n",
       "       [0.9802163 ],\n",
       "       [0.9640935 ],\n",
       "       [0.96826077],\n",
       "       [0.01773201],\n",
       "       [0.03182798],\n",
       "       [0.03275581],\n",
       "       [0.9747136 ],\n",
       "       [0.03410263],\n",
       "       [0.9694521 ],\n",
       "       [0.98187846],\n",
       "       [0.04734024],\n",
       "       [0.9553295 ],\n",
       "       [0.04374054],\n",
       "       [0.96287215],\n",
       "       [0.01919892],\n",
       "       [0.9885804 ],\n",
       "       [0.9651734 ],\n",
       "       [0.95930284],\n",
       "       [0.05134711],\n",
       "       [0.01817818],\n",
       "       [0.9519765 ],\n",
       "       [0.01636206],\n",
       "       [0.9876782 ],\n",
       "       [0.04819407],\n",
       "       [0.01587076],\n",
       "       [0.9683981 ],\n",
       "       [0.03627622],\n",
       "       [0.02989552],\n",
       "       [0.01564344],\n",
       "       [0.04087048],\n",
       "       [0.02781957],\n",
       "       [0.03322211],\n",
       "       [0.01753939],\n",
       "       [0.9705697 ],\n",
       "       [0.02732892],\n",
       "       [0.9686624 ],\n",
       "       [0.96140754],\n",
       "       [0.9726044 ],\n",
       "       [0.01351181],\n",
       "       [0.96690714],\n",
       "       [0.02892907],\n",
       "       [0.0218842 ],\n",
       "       [0.0293878 ],\n",
       "       [0.9666542 ],\n",
       "       [0.9743908 ],\n",
       "       [0.15040617],\n",
       "       [0.06598814],\n",
       "       [0.96337014],\n",
       "       [0.96416736],\n",
       "       [0.9734287 ],\n",
       "       [0.02190975],\n",
       "       [0.03515939],\n",
       "       [0.96872324],\n",
       "       [0.04507743],\n",
       "       [0.02606178],\n",
       "       [0.01479196],\n",
       "       [0.92683357],\n",
       "       [0.9838466 ],\n",
       "       [0.9751692 ],\n",
       "       [0.03891057],\n",
       "       [0.9562472 ],\n",
       "       [0.02296208],\n",
       "       [0.9708248 ],\n",
       "       [0.05649928],\n",
       "       [0.03449548],\n",
       "       [0.9489329 ],\n",
       "       [0.01336206],\n",
       "       [0.03984084],\n",
       "       [0.02647843],\n",
       "       [0.96328855],\n",
       "       [0.04090476],\n",
       "       [0.02153989],\n",
       "       [0.03357477],\n",
       "       [0.9861986 ],\n",
       "       [0.9748747 ],\n",
       "       [0.02798478],\n",
       "       [0.93736774],\n",
       "       [0.02291718],\n",
       "       [0.97395456],\n",
       "       [0.9273652 ],\n",
       "       [0.9540234 ],\n",
       "       [0.9589577 ],\n",
       "       [0.96280015],\n",
       "       [0.95455134],\n",
       "       [0.9596254 ],\n",
       "       [0.9889088 ],\n",
       "       [0.0290905 ],\n",
       "       [0.98311526],\n",
       "       [0.97181076],\n",
       "       [0.03714564],\n",
       "       [0.01783029],\n",
       "       [0.03485015],\n",
       "       [0.03074754],\n",
       "       [0.0364573 ],\n",
       "       [0.9476057 ],\n",
       "       [0.97184163],\n",
       "       [0.03582355],\n",
       "       [0.01803967],\n",
       "       [0.01915703],\n",
       "       [0.95180815],\n",
       "       [0.98809326],\n",
       "       [0.9574585 ],\n",
       "       [0.98117113],\n",
       "       [0.03484784],\n",
       "       [0.03863072],\n",
       "       [0.01426073],\n",
       "       [0.94001114],\n",
       "       [0.94756305],\n",
       "       [0.98099434],\n",
       "       [0.02743134],\n",
       "       [0.95382756],\n",
       "       [0.9679599 ],\n",
       "       [0.9763436 ],\n",
       "       [0.01536458],\n",
       "       [0.04752236],\n",
       "       [0.03062131],\n",
       "       [0.02821061],\n",
       "       [0.9758751 ],\n",
       "       [0.018435  ],\n",
       "       [0.05102997],\n",
       "       [0.98894376],\n",
       "       [0.9718053 ],\n",
       "       [0.9584909 ],\n",
       "       [0.03289887],\n",
       "       [0.0176699 ],\n",
       "       [0.02679863],\n",
       "       [0.9766778 ],\n",
       "       [0.98580486],\n",
       "       [0.04625377],\n",
       "       [0.01909133],\n",
       "       [0.9549472 ],\n",
       "       [0.96437544],\n",
       "       [0.04475217],\n",
       "       [0.9718356 ],\n",
       "       [0.9775691 ],\n",
       "       [0.9650234 ],\n",
       "       [0.01252883],\n",
       "       [0.02193016],\n",
       "       [0.0284048 ],\n",
       "       [0.03092479],\n",
       "       [0.96220076],\n",
       "       [0.9716454 ],\n",
       "       [0.03344466],\n",
       "       [0.01025267],\n",
       "       [0.95370406],\n",
       "       [0.97062534],\n",
       "       [0.9649    ],\n",
       "       [0.02370774],\n",
       "       [0.96941596],\n",
       "       [0.041762  ],\n",
       "       [0.01255038],\n",
       "       [0.9824747 ],\n",
       "       [0.9758742 ],\n",
       "       [0.96795267],\n",
       "       [0.93833053],\n",
       "       [0.9670416 ],\n",
       "       [0.962074  ],\n",
       "       [0.05822522],\n",
       "       [0.98055184],\n",
       "       [0.9469219 ],\n",
       "       [0.03973375],\n",
       "       [0.9765215 ],\n",
       "       [0.01069634],\n",
       "       [0.02636241],\n",
       "       [0.02776743],\n",
       "       [0.95539665],\n",
       "       [0.0126036 ],\n",
       "       [0.94676936],\n",
       "       [0.0363417 ],\n",
       "       [0.9836101 ],\n",
       "       [0.96623826],\n",
       "       [0.98449147],\n",
       "       [0.95173764],\n",
       "       [0.02262213],\n",
       "       [0.04076098],\n",
       "       [0.9638477 ],\n",
       "       [0.9792516 ],\n",
       "       [0.97974735],\n",
       "       [0.9692957 ],\n",
       "       [0.98262686],\n",
       "       [0.01364851],\n",
       "       [0.01732004],\n",
       "       [0.02201965],\n",
       "       [0.9849085 ],\n",
       "       [0.03147781],\n",
       "       [0.02393748],\n",
       "       [0.963899  ],\n",
       "       [0.03281386],\n",
       "       [0.95795965],\n",
       "       [0.02227703],\n",
       "       [0.9628907 ],\n",
       "       [0.03031977],\n",
       "       [0.9506885 ],\n",
       "       [0.03360016],\n",
       "       [0.03790386],\n",
       "       [0.03433681],\n",
       "       [0.03460284],\n",
       "       [0.0353467 ],\n",
       "       [0.9550535 ],\n",
       "       [0.01623828],\n",
       "       [0.04827366],\n",
       "       [0.03232556],\n",
       "       [0.0479783 ],\n",
       "       [0.97808737],\n",
       "       [0.98990613],\n",
       "       [0.03208325],\n",
       "       [0.9619656 ],\n",
       "       [0.98592645],\n",
       "       [0.0184196 ],\n",
       "       [0.04147698],\n",
       "       [0.03619381],\n",
       "       [0.02518969],\n",
       "       [0.9818267 ],\n",
       "       [0.97421515],\n",
       "       [0.9634068 ],\n",
       "       [0.97196937],\n",
       "       [0.02969244],\n",
       "       [0.97184455],\n",
       "       [0.95707947],\n",
       "       [0.03039592],\n",
       "       [0.03320116],\n",
       "       [0.9446618 ],\n",
       "       [0.02108723],\n",
       "       [0.01352919],\n",
       "       [0.01399158],\n",
       "       [0.02987731],\n",
       "       [0.01899325],\n",
       "       [0.02805315],\n",
       "       [0.05816301],\n",
       "       [0.9791797 ],\n",
       "       [0.9532425 ],\n",
       "       [0.9846273 ],\n",
       "       [0.9649202 ],\n",
       "       [0.01485998],\n",
       "       [0.9590459 ],\n",
       "       [0.95857644],\n",
       "       [0.04227174],\n",
       "       [0.975655  ],\n",
       "       [0.96075946],\n",
       "       [0.9716025 ],\n",
       "       [0.01994811],\n",
       "       [0.02209143],\n",
       "       [0.02297995],\n",
       "       [0.9820331 ],\n",
       "       [0.95766443],\n",
       "       [0.03213648],\n",
       "       [0.04404572],\n",
       "       [0.02873061],\n",
       "       [0.9730732 ],\n",
       "       [0.956117  ],\n",
       "       [0.97824645],\n",
       "       [0.01499494],\n",
       "       [0.01820839],\n",
       "       [0.02348728],\n",
       "       [0.02626171],\n",
       "       [0.9799088 ],\n",
       "       [0.01461534],\n",
       "       [0.02773961],\n",
       "       [0.96647394],\n",
       "       [0.03394135],\n",
       "       [0.03574243],\n",
       "       [0.98542434],\n",
       "       [0.0432255 ],\n",
       "       [0.0389908 ],\n",
       "       [0.9751726 ],\n",
       "       [0.9563996 ],\n",
       "       [0.955723  ],\n",
       "       [0.01975865],\n",
       "       [0.9559993 ],\n",
       "       [0.01927276],\n",
       "       [0.03821665],\n",
       "       [0.03981325],\n",
       "       [0.961432  ],\n",
       "       [0.97247267],\n",
       "       [0.05393491],\n",
       "       [0.97753674],\n",
       "       [0.02368668],\n",
       "       [0.02405804],\n",
       "       [0.01615057],\n",
       "       [0.9746088 ],\n",
       "       [0.9474901 ],\n",
       "       [0.01825669],\n",
       "       [0.03778011],\n",
       "       [0.03000535],\n",
       "       [0.97375995],\n",
       "       [0.04961796],\n",
       "       [0.9612075 ],\n",
       "       [0.9598196 ],\n",
       "       [0.04654296],\n",
       "       [0.95658046],\n",
       "       [0.9672347 ],\n",
       "       [0.03347292],\n",
       "       [0.01108133],\n",
       "       [0.9805128 ],\n",
       "       [0.02735597],\n",
       "       [0.02684126],\n",
       "       [0.96717554],\n",
       "       [0.9450131 ],\n",
       "       [0.03571386],\n",
       "       [0.971216  ],\n",
       "       [0.05506199],\n",
       "       [0.03179354],\n",
       "       [0.02447031],\n",
       "       [0.96169794],\n",
       "       [0.97974336],\n",
       "       [0.9606558 ],\n",
       "       [0.984487  ],\n",
       "       [0.98542696],\n",
       "       [0.02359154],\n",
       "       [0.01746521],\n",
       "       [0.04142413],\n",
       "       [0.9735929 ],\n",
       "       [0.9886536 ],\n",
       "       [0.97528034],\n",
       "       [0.01578525],\n",
       "       [0.9592776 ],\n",
       "       [0.03109617],\n",
       "       [0.9773792 ],\n",
       "       [0.03656172],\n",
       "       [0.9693377 ],\n",
       "       [0.01725785],\n",
       "       [0.01120637],\n",
       "       [0.9848804 ],\n",
       "       [0.9679323 ],\n",
       "       [0.95373726],\n",
       "       [0.04420043],\n",
       "       [0.9834648 ],\n",
       "       [0.9852701 ],\n",
       "       [0.9689327 ],\n",
       "       [0.01751051],\n",
       "       [0.96997166]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "55bd1fc1-c122-4396-beb9-e31df9f6aa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "88e74f3f-1a68-449f-8664-24700c24074f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the the number of inputs (features) to the model\n",
    "number_input_features = len(X_train.iloc[0])\n",
    "\n",
    "# Review the number of features\n",
    "number_input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "06662653-db17-4f3f-9085-62d0468901b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of neurons in the output layer\n",
    "number_output_neurons_A1 = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b7651cbe-65b9-47e2-9000-8b500e689178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the first hidden layer\n",
    "hidden_nodes_layer1_A1 = 20\n",
    "\n",
    "# Review the number of hidden nodes in the first layer\n",
    "hidden_nodes_layer1_A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef4abca5-4d52-4e56-a877-16034d4aa455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Sequential model instance\n",
    "nn_A1 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c761dc02-2770-4d8b-a340-b1a2828a9bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Model.summary of <keras.engine.sequential.Sequential object at 0x000001540E4B5490>>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First hidden layer\n",
    "nn_A1.add(Dense(units=hidden_nodes_layer1_A1, input_dim=number_input_features, activation=\"sigmoid\"))\n",
    "\n",
    "# Output layer\n",
    "nn_A1.add(Dense(units= number_output_neurons_A1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_A1.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b9f7f8d0-af1d-48ca-bbe0-9f86dc6a6aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Sequential model\n",
    "nn_A1.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b3bd8a4-723f-47c7-aa6b-b58384f0b6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.6427e-04 - accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2120e-04 - accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.8056e-04 - accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4250e-04 - accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.0640e-04 - accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.7275e-04 - accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.4031e-04 - accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0994e-04 - accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.8124e-04 - accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5418e-04 - accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.2816e-04 - accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.0372e-04 - accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.8022e-04 - accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5802e-04 - accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3693e-04 - accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.1676e-04 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.9757e-04 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7928e-04 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.6191e-04 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.4533e-04 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2942e-04 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1421e-04 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9966e-04 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8582e-04 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.7246e-04 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5976e-04 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.4752e-04 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3586e-04 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.2466e-04 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.1392e-04 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.0360e-04 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9371e-04 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8418e-04 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.7499e-04 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.6622e-04 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5772e-04 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4956e-04 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4171e-04 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3414e-04 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2684e-04 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1988e-04 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1307e-04 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0658e-04 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0032e-04 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9424e-04 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8841e-04 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8276e-04 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Fit the model using 50 epochs and the training data\n",
    "fit_model_A1 = nn.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2bda4fc4-f824-43fc-a1b6-0c7239f9931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6b35894c-5f75-4094-8c38-547df695785f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the the number of inputs (features) to the model\n",
    "number_input_features = len(X_train.iloc[0])\n",
    "\n",
    "# Review the number of features\n",
    "number_input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b91526db-bfca-4eed-a195-a6bda51546c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of neurons in the output layer\n",
    "number_output_neurons_A2 = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2e4b4fa0-0762-49b7-bbc2-eb1ab8dc1a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the first hidden layer\n",
    "hidden_nodes_layer1_A2 = 50\n",
    "\n",
    "# Review the number of hidden nodes in the first layer\n",
    "hidden_nodes_layer1_A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a632d9e-e105-47f5-bd8e-ffd758632c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Sequential model instance\n",
    "nn_A2 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "31cf3390-2e6f-43c1-a9c8-aa7f7b5df8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Model.summary of <keras.engine.sequential.Sequential object at 0x000001540D4540A0>>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First hidden layer\n",
    "nn_A2.add(Dense(units=hidden_nodes_layer1_A2, input_dim=number_input_features, activation=\"softmax\"))\n",
    "\n",
    "# Output layer\n",
    "nn_A2.add(Dense(units= number_output_neurons_A1, activation=\"softmax\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_A2.summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5dc6e1dd-c64b-415a-a19c-d2c101064215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Sequential model\n",
    "nn_A2.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d9f747f4-755e-40f6-8c43-73d77834eccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7734e-04 - accuracy: 1.0000\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7208e-04 - accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6703e-04 - accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6210e-04 - accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5736e-04 - accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5279e-04 - accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.4837e-04 - accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.4409e-04 - accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.3997e-04 - accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.3597e-04 - accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.3210e-04 - accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2837e-04 - accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2474e-04 - accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2122e-04 - accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.1784e-04 - accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.1453e-04 - accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.1133e-04 - accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.0823e-04 - accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.0524e-04 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.0233e-04 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.9533e-05 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.6802e-05 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4158e-05 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1587e-05 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9104e-05 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.6695e-05 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4361e-05 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.2082e-05 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9874e-05 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.7727e-05 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.5652e-05 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3636e-05 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1677e-05 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.9778e-05 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.7934e-05 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.6146e-05 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4408e-05 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.2709e-05 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1062e-05 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.9471e-05 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.7917e-05 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.6410e-05 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.4939e-05 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3525e-05 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.2137e-05 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 5.0783e-05 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 4.9470e-05 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 4.8198e-05 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 4.6957e-05 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 4.5757e-05 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "fit_model_A2 = nn.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cf09a5d4-ad31-4af0-8cae-0110e65a5f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the results of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a8e891a8-d369-448f-81eb-9fc57c51ae27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Model Results\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 4.5127e-05 - accuracy: 1.0000\n",
      "Loss: 4.512664600042626e-05, Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Model Results\")\n",
    "\n",
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "# Display the model loss and accuracy results\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "318dcfcd-f192-48bc-a4dc-fc5ebf9cac0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternative Model 1 Results\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\justi\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1852, in test_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\justi\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1836, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\justi\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1824, in run_step  **\n        outputs = model.test_step(data)\n    File \"C:\\Users\\justi\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in test_step\n        self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\justi\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\justi\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\justi\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\justi\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\justi\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1984, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\justi\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5559, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 3) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_34096\\3713250288.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn_A1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Display the model loss and accuracy results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__test_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\justi\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1852, in test_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\justi\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1836, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\justi\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1824, in run_step  **\n        outputs = model.test_step(data)\n    File \"C:\\Users\\justi\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in test_step\n        self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\justi\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\justi\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\justi\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\justi\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\justi\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1984, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\justi\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5559, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 3) are incompatible\n"
     ]
    }
   ],
   "source": [
    "print(\"Alternative Model 1 Results\")\n",
    "\n",
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = nn_A1.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "# Display the model loss and accuracy results\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd95f7ba-f112-4e3d-91a0-7321cd0a6a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Alternative Model 2 Results\")\n",
    "\n",
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = nn_A2.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "# Display the model loss and accuracy results\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
